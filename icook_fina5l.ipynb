{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwhile(page <= max_page):\\n    page_index = f\\'?page={page}\\'\\n    url = domain + url + page_index\\n    print(f\"URL: {url}\")\\n    random_headers()\\n    headers=headers\\n    get_soup(url,headers)\\n    soup=get_soup(url,headers)\\n    food_list = soup.select(\\'a.browse-recipe-touch-link\\')\\n    for food in food_list:\\n        url = \\'https://icook.tw/\\' + food[\\'href\\']\\n         \\n        random_headers()\\n        headers=headers\\n        get_soup(url,headers)\\n        soup=get_soup(url,headers)\\n        print(url)\\n        #recipe_title = \"\".join((soup_recipe.select(\\'h1.title\\')[0].text).split())\\n        #recipe_title = preprocess(recipe_title)\\n        recipe_title = soup.select(\\'h1.title\\')[0].text\\n        recipe_title = preprocess(recipe_title)\\n        check_vip=soup.select(\\'h1.title\\')[0].select(\\'span.badge-vip\\')\\n        if len(check_vip)<=0:\\n            pass\\n            #print(\"is not vip data, data will be save\")\\n        else:\\n            print(\"this is vip data,data will not save\")\\n            vip_count+=1\\n            continue\\n        recipe_author = soup.select(\\'a.author-name-link\\')[0].text\\n        recipe_pic_url = soup.select(\"img.main-pic\")[0][\\'src\\']\\n        \\n    \\n        if len(soup.select(\\'span.stat-content\\')) == 2:\\n            recipe_like = 0\\n        else:\\n            if \\'萬\\' in soup.select(\\'span.stat-content\\')[0].text:\\n                recipe_like = int(soup.select(\\'span.stat-content\\')[0].text[:-5].replace(\\'.\\',\\'\\')+\"000\")\\n            else:\\n                recipe_like = int(soup.select(\\'span.stat-content\\')[0].text[:-3].replace(\\',\\',\\'\\'))\\n        \\n        if not soup.select(\\'div.servings-info.info-block\\') and not soup.select(\\'div.time-info.info-block\\'):\\n            recipe_servings = 0\\n            recipe_time = 0\\n        elif not soup.select(\\'div.time-info.info-block\\'):\\n            recipe_servings = int(soup.select(\\'span.num\\')[0].text)\\n            recipe_time = 0\\n        elif  not soup.select(\\'div.servings-info.info-block\\'): \\n            recipe_servings = 0\\n            recipe_time = int(soup.select(\\'span.num\\')[0].text)\\n        else: \\n            recipe_servings = int(soup.select(\\'span.num\\')[0].text)\\n            recipe_time = int(soup.select(\\'span.num\\')[1].text)\\n\\n        recipe_ingredient = \"\"\\n        for ingredient in soup.select(\\'.ingredient-search\\'):\\n            if ingredient.text == \"請參考圖片說明\":\\n                continue\\n            else:\\n                recipe_ingredient += ingredient.text + \" \" \\n        recipe_ingredient = emoji.get_emoji_regexp().sub(r\\'\\', recipe_ingredient)\\n        \\n        recipe_unit = \"\"\\n        for unit in soup.select(\\'div.ingredient-unit\\'):\\n            if unit.text == \"内文有\":\\n                continue\\n            else:\\n                recipe_unit += unit.text + \" \"\\n\\n        recipe_steps = \"\"\\n        counter = 1\\n        for steps in soup.select(\\'div.step-instruction-content\\'):\\n            recipe_steps += str(counter) + \" \" + steps.text + \"\\n\"\\n            recipe_steps = emoji.get_emoji_regexp().sub(r\\'\\', recipe_steps)\\n            counter += 1\\n            \\n        publish_date = soup.select(\\'span.meta-content\\')\\n        if len (publish_date)<=0:\\n            print(\"publish_date is na\")\\n            publish_date=\"na\"\\n        else:\\n            publish_date = publish_date[0].text[:-3]\\n        \\n        views = soup_.select(\\'span.meta-content\\')\\n        if len(views)<=0:\\n            print(\"view is na\")\\n            views_number=0\\n            views=\"0\"\\n        else:\\n            views=views[1].text[:-3]\\n            if \\'萬\\' in views:\\n                views_number = views[:-2]\\n                views_number = int(views_number.replace(\\'.\\',\\'\\')+\"000\")\\n            else:\\n                views_number = int(views.replace(\\',\\',\\'\\'))\\n        \\n        \\n        \\n        #print(recipe_section)    \\n        #print(recipe_url)\\n        #print(recipe_title)\\n        #print(recipe_author)\\n        #print(recipe_pic_url)\\n        \\n        print(recipe_like)\\n        #print(recipe_servings)\\n        #print(recipe_time)\\n        #print(recipe_ingredient)\\n        #print(recipe_unit)\\n        #print(recipe_steps)\\n        print(publish_date)\\n        #print(views)\\n        print(\"----\")\\n        \\n        ls = [recipe_title,recipe_author,recipe_url,recipe_pic_url,recipe_servings,recipe_time,recipe_ingredient,              recipe_unit,recipe_like,publish_date,views_number,recipe_steps]\\n        df.loc[c] = ls\\n        c += 1\\n    \\n        time.sleep(random.randint(1,4))\\n    page += 1        \\ndf\\nprint(\\'有多少vip資料{}\\'.format(vip_count))\\ntime_end = time.time()\\nprint(time_end - time_start)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import emoji\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def random_headers():\n",
    "    headers_list = [{'User-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0'},{'User-agent':' Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'},{'User-agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36 OPR/38.0.2220.41'},{'User-agent':'Mozilla/5.0 (Linux; U; Android 4.0.3; de-ch; HTC Sensation Build/IML74K) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30'},{'User-agent':'Mozilla/5.0 (compatible; MSIE 9.0; Windows Phone OS 7.5; Trident/5.0; IEMobile/9.0)'}]\n",
    "    headers=random.choice(headers_list)\n",
    "    #print(headers)\n",
    "    return headers\n",
    "    \n",
    "\n",
    "  \n",
    "def get_soup(url,headers):\n",
    "    ss=requests.session()\n",
    "    res=ss.get(url,headers=headers)\n",
    "    \n",
    "    res_status_code=res.status_code\n",
    "    print(res_status_code)\n",
    "    \n",
    "    if res_status_code!=200:\n",
    "        proxy_list=[{'https':'59.124.224.180:3128','http':'59.124.224.180:3128'},{'https':'113.196.140.162:8888','http':'113.196.140.162:8888'}]\n",
    "        proxy_list2={'http':'http://220.135.165.38:8080','https':'220.135.168.38:8080'}\n",
    "        proxy=random.choice(proxy_list)\n",
    "        \n",
    "        print(\"進入proxy狀態,ip已經被鎖定\")\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            \n",
    "            res = requests.get(url ,proxies=proxy ,headers=headers)\n",
    "            res_status_code=res.status_code\n",
    "            print(proxy)\n",
    "            print(res_status_code)\n",
    "            #print(res.status_code)\n",
    "            \n",
    "            soup=BeautifulSoup(res.text,'html.parser')\n",
    "            return soup\n",
    "            \n",
    "            #print(res.json())    \n",
    "   \n",
    "        except Exception as e:\n",
    "            proxy=proxy_list2\n",
    "            time.sleep(5)\n",
    "            res = requests.get(url ,proxies=proxy ,headers=headers)\n",
    "            res_status_code=res.status_code\n",
    "            print(res_status_code)\n",
    "           \n",
    "            print(\"這是備源proxy\")\n",
    "            res_status_code=res.status_code\n",
    "            if res_status_code!=200:\n",
    "                print(\"所有proxy失效,程式終止\")\n",
    "                \n",
    "            else:\n",
    "              \n",
    "                soup=BeautifulSoup(res.text,'html.parser')\n",
    "                return soup\n",
    "           \n",
    "    \n",
    "    else:\n",
    "        \n",
    "       \n",
    "        #print(ss.cookies.get_dict())\n",
    "\n",
    "        #res=ss.get(url,headers=headers)\n",
    "        soup=BeautifulSoup(res.text,'html.parser')\n",
    "        return soup\n",
    "\n",
    "def preprocess (x):\n",
    "    x = emoji.get_emoji_regexp().sub(r'', x)\n",
    "    x = re.sub(r'[［(（【{][^】)}）］]*[】)}）］]', '', x)\n",
    "    x = x.strip().replace(\" \", \"\")\n",
    "    x = re.sub(r'[~\\-。]', \"\", x) \n",
    "    return x\n",
    "\n",
    "headers = {'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "domain = 'https://icook.tw/'\n",
    "url = 'categories/455'\n",
    "\n",
    "c = 0\n",
    "url = domain + url\n",
    "df = pd.DataFrame(columns = ['Recipe Name','Author','Recipe URL','Recipe Picture','Servings','Time','Ingredients',\\\n",
    "                             'Unit','Recipe Like','Publish Date','Views Number','Recipe Steps'])\n",
    "\n",
    "headers=random_headers()\n",
    "soup=get_soup(url,headers)\n",
    "vip_count=0\n",
    "page = 1\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "total_amount = soup.select('title')[0].text\n",
    "total_amount = int(''.join(re.findall(\"\\d+\", total_amount)))\n",
    "max_page = 0\n",
    "if total_amount % 18 == 0:\n",
    "    max_page = total_amount // 18\n",
    "else:\n",
    "    max_page = (total_amount // 18) + 1\n",
    "\n",
    "\n",
    "\n",
    "while(page <= max_page):\n",
    "    page_index = f'?page={page}'\n",
    "    url = domain + url + page_index\n",
    "    print(f\"URL: {url}\")\n",
    "    \n",
    "    headers=random_headers()\n",
    "    soup=get_soup(url,headers)\n",
    "    food_list = soup.select('a.browse-recipe-touch-link')\n",
    "    for food in food_list:\n",
    "        url = 'https://icook.tw/' + food['href']\n",
    "         headers=random_headers()\n",
    "        soup=get_soup(url,headers)\n",
    "        print(url)\n",
    "        #recipe_title = \"\".join((soup_recipe.select('h1.title')[0].text).split())\n",
    "        #recipe_title = preprocess(recipe_title)\n",
    "        recipe_title = soup.select('h1.title')[0].text\n",
    "        recipe_title = preprocess(recipe_title)\n",
    "        check_vip=soup.select('h1.title')[0].select('span.badge-vip')\n",
    "        if len(check_vip)<=0:\n",
    "            pass\n",
    "            #print(\"is not vip data, data will be save\")\n",
    "        else:\n",
    "            print(\"this is vip data,data will not save\")\n",
    "            vip_count+=1\n",
    "            continue\n",
    "        recipe_author = soup.select('a.author-name-link')[0].text\n",
    "        recipe_pic_url = soup.select(\"img.main-pic\")[0]['src']\n",
    "        \n",
    "    \n",
    "        if len(soup.select('span.stat-content')) == 2:\n",
    "            recipe_like = 0\n",
    "        else:\n",
    "            if '萬' in soup.select('span.stat-content')[0].text:\n",
    "                recipe_like = int(soup.select('span.stat-content')[0].text[:-5].replace('.','')+\"000\")\n",
    "            else:\n",
    "                recipe_like = int(soup.select('span.stat-content')[0].text[:-3].replace(',',''))\n",
    "        \n",
    "        if not soup.select('div.servings-info.info-block') and not soup.select('div.time-info.info-block'):\n",
    "            recipe_servings = 0\n",
    "            recipe_time = 0\n",
    "        elif not soup.select('div.time-info.info-block'):\n",
    "            recipe_servings = int(soup.select('span.num')[0].text)\n",
    "            recipe_time = 0\n",
    "        elif  not soup.select('div.servings-info.info-block'): \n",
    "            recipe_servings = 0\n",
    "            recipe_time = int(soup.select('span.num')[0].text)\n",
    "        else: \n",
    "            recipe_servings = int(soup.select('span.num')[0].text)\n",
    "            recipe_time = int(soup.select('span.num')[1].text)\n",
    "\n",
    "        recipe_ingredient = \"\"\n",
    "        for ingredient in soup.select('.ingredient-search'):\n",
    "            if ingredient.text == \"請參考圖片說明\":\n",
    "                continue\n",
    "            else:\n",
    "                recipe_ingredient += ingredient.text + \" \" \n",
    "        recipe_ingredient = emoji.get_emoji_regexp().sub(r'', recipe_ingredient)\n",
    "        \n",
    "        recipe_unit = \"\"\n",
    "        for unit in soup.select('div.ingredient-unit'):\n",
    "            if unit.text == \"内文有\":\n",
    "                continue\n",
    "            else:\n",
    "                recipe_unit += unit.text + \" \"\n",
    "\n",
    "        recipe_steps = \"\"\n",
    "        counter = 1\n",
    "        for steps in soup.select('div.step-instruction-content'):\n",
    "            recipe_steps += str(counter) + \" \" + steps.text + \"\\n\"\n",
    "            recipe_steps = emoji.get_emoji_regexp().sub(r'', recipe_steps)\n",
    "            counter += 1\n",
    "            \n",
    "        publish_date = soup.select('span.meta-content')\n",
    "        if len (publish_date)<=0:\n",
    "            print(\"publish_date is na\")\n",
    "            publish_date=\"na\"\n",
    "        else:\n",
    "            publish_date = publish_date[0].text[:-3]\n",
    "        \n",
    "        views = soup_.select('span.meta-content')\n",
    "        if len(views)<=0:\n",
    "            print(\"view is na\")\n",
    "            views_number=0\n",
    "            views=\"0\"\n",
    "        else:\n",
    "            views=views[1].text[:-3]\n",
    "            if '萬' in views:\n",
    "                views_number = views[:-2]\n",
    "                views_number = int(views_number.replace('.','')+\"000\")\n",
    "            else:\n",
    "                views_number = int(views.replace(',',''))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(recipe_section)    \n",
    "        #print(recipe_url)\n",
    "        #print(recipe_title)\n",
    "        #print(recipe_author)\n",
    "        #print(recipe_pic_url)\n",
    "        \n",
    "        print(recipe_like)\n",
    "        #print(recipe_servings)\n",
    "        #print(recipe_time)\n",
    "        #print(recipe_ingredient)\n",
    "        #print(recipe_unit)\n",
    "        #print(recipe_steps)\n",
    "        print(publish_date)\n",
    "        #print(views)\n",
    "        print(\"----\")\n",
    "        \n",
    "        ls = [recipe_title,recipe_author,recipe_url,recipe_pic_url,recipe_servings,recipe_time,recipe_ingredient,\\\n",
    "              recipe_unit,recipe_like,publish_date,views_number,recipe_steps]\n",
    "        df.loc[c] = ls\n",
    "        c += 1\n",
    "    \n",
    "        time.sleep(random.randint(1,4))\n",
    "    page += 1        \n",
    "df\n",
    "print('有多少vip資料{}'.format(vip_count))\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'./{section_number}.csv', index=False ,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://icook.tw/'\n",
    "url = 'categories/455'\n",
    "\n",
    "c = 0\n",
    "url = domain + url\n",
    "\n",
    "\n",
    "ss=requests.session()\n",
    "res=ss.get(url,headers=headers)\n",
    "    \n",
    "res_status_code=res.status_code\n",
    "print(res_status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
