{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mport threading\n",
    "import time\n",
    "import emoji\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {'User-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0'}\n",
    "section_url = 'https://icook.tw/categories?ref=icook-footer'\n",
    "\n",
    "res = requests.get(section_url, headers=headers)\n",
    "soup_section = BeautifulSoup(res.text,'html.parser')\n",
    "tag_list = soup_section.select('a.categories-all-child-link')\n",
    "section_ls = []\n",
    "for tag in tag_list:\n",
    "    section_ls.append(tag['href'])\n",
    "\n",
    "your_section = section_ls[len(section_ls)//2:]\n",
    "your_section=your_section[4:8]\n",
    "\n",
    "def preprocess (x):\n",
    "    x = emoji.get_emoji_regexp().sub(r'', x)\n",
    "    x = re.sub(r'[［(（【{][^】)}）］]*[】)}）］]', '', x)\n",
    "    x = x.strip().replace(\" \", \"\")\n",
    "    x = re.sub(r'[~\\-。]', \"\", x) \n",
    "    return x\n",
    "\n",
    "def job(x):\n",
    "    #headers = {'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "    domain = 'https://icook.tw'\n",
    "    url = x\n",
    "    page_index = 1\n",
    "    c = 0\n",
    "    full_url = domain + url\n",
    "    df = pd.DataFrame(columns = ['Recipe Name','Author','Recipe URL','Recipe Picture','Servings','Time','Ingredients',\\\n",
    "                                 'Unit','Recipe Like','Publish Date','Views Number','Recipe Steps'])\n",
    "    res = requests.get(full_url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "    section_number = url.split('/')[2]\n",
    "\n",
    "    while(full_url != domain):\n",
    "        print(f\"URL: {full_url}\")\n",
    "        res = requests.get(full_url, headers=headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        food_list = soup.select('a.browse-recipe-touch-link')\n",
    "        for food in food_list:\n",
    "            recipe_url = 'https://icook.tw/' + food['href']\n",
    "            res_recipe = requests.get(recipe_url,headers=headers)\n",
    "            soup_recipe = BeautifulSoup(res_recipe.text,'html.parser')\n",
    "            #recipe_section = soup_recipe.select('a.recipe-breadcrumb-item-link')[1].text.strip()\n",
    "            recipe_title = \"\".join((soup_recipe.select('h1.title')[0].text).split())\n",
    "            recipe_title = preprocess(recipe_title)\n",
    "            recipe_author = soup_recipe.select('a.author-name-link')[0].text\n",
    "            recipe_pic_url = soup_recipe.select(\"img.main-pic\")[0]['src']\n",
    "            \n",
    "        \n",
    "            if len(soup_recipe.select('span.stat-content')) == 2:\n",
    "                recipe_like = 0\n",
    "            else:\n",
    "                if '萬' in soup_recipe.select('span.stat-content')[0].text:\n",
    "                    recipe_like = int(soup_recipe.select('span.stat-content')[0].text[:-5].replace('.','')+\"000\")\n",
    "                else:\n",
    "                    recipe_like = int(soup_recipe.select('span.stat-content')[0].text[:-3].replace(',',''))\n",
    "        \n",
    "            if not soup_recipe.select('div.servings-info.info-block') and not soup_recipe.select('div.time-info.info-block'):\n",
    "                recipe_servings = 0\n",
    "                recipe_time = 0\n",
    "            elif not soup_recipe.select('div.time-info.info-block'):\n",
    "                recipe_servings = int(soup_recipe.select('span.num')[0].text)\n",
    "                recipe_time = 0\n",
    "            elif  not soup_recipe.select('div.servings-info.info-block'): \n",
    "                recipe_servings = 0\n",
    "                recipe_time = int(soup_recipe.select('span.num')[0].text)\n",
    "            else: \n",
    "                recipe_servings = int(soup_recipe.select('span.num')[0].text)\n",
    "                recipe_time = int(soup_recipe.select('span.num')[1].text)\n",
    "\n",
    "            recipe_ingredient = \"\"\n",
    "            for ingredient in soup_recipe.select('.ingredient-search'):\n",
    "                if ingredient.text == \"請參考圖片說明\":\n",
    "                    continue\n",
    "                else:\n",
    "                    recipe_ingredient += ingredient.text + \" \" \n",
    "            recipe_ingredient = emoji.get_emoji_regexp().sub(r'', recipe_ingredient)\n",
    "        \n",
    "            recipe_unit = \"\"\n",
    "            for unit in soup_recipe.select('div.ingredient-unit'):\n",
    "                if unit.text == \"内文有\":\n",
    "                    continue\n",
    "                else:\n",
    "                    recipe_unit += unit.text + \" \"\n",
    "\n",
    "            recipe_steps = \"\"\n",
    "            counter = 1\n",
    "            for steps in soup_recipe.select('div.step-instruction-content'):\n",
    "                recipe_steps += str(counter) + \" \" + steps.text + \"\\n\"\n",
    "                recipe_steps = emoji.get_emoji_regexp().sub(r'', recipe_steps)\n",
    "                counter += 1\n",
    "            \n",
    "            publish_date = soup_recipe.select('span.meta-content')[0].text[:-3]\n",
    "            views = soup_recipe.select('span.meta-content')[1].text[:-3]\n",
    "            #print(views)\n",
    "        \n",
    "            if '萬' in views:\n",
    "                views_number = views[:-2]\n",
    "                views_number = int(views_number.replace('.','')+\"000\")\n",
    "            else:\n",
    "                views_number = int(views.replace(',',''))\n",
    "        \n",
    "        \n",
    "            \n",
    "            #print(recipe_section)    \n",
    "            print(recipe_url)\n",
    "            #print(recipe_title)\n",
    "            #print(recipe_author)\n",
    "            #print(recipe_pic_url)\n",
    "            #print(recipe_like)\n",
    "            #print(recipe_servings)\n",
    "            #print(recipe_time)\n",
    "            #print(recipe_ingredient)\n",
    "            #print(recipe_unit)\n",
    "            #print(recipe_steps)\n",
    "            #print(publish_date)\n",
    "            #print(views)\n",
    "            \n",
    "        \n",
    "            ls = [recipe_title,recipe_author,recipe_url,recipe_pic_url,recipe_servings,recipe_time,recipe_ingredient,\\\n",
    "                  recipe_unit,recipe_like,publish_date,views_number,recipe_steps]\n",
    "            df.loc[c] = ls\n",
    "            c += 1\n",
    "    \n",
    "            time.sleep(random.randint(2, 5))\n",
    "        \n",
    "        pages = soup.select('a[rel=\"next\"]')\n",
    "    \n",
    "        if len(pages) != 0:\n",
    "            print(pages)\n",
    "            page = pages[0][\"href\"]\n",
    "            full_url = domain + page\n",
    "            #time.sleep(random.randint(1, 3))\n",
    "        else:\n",
    "            full_url = domain\n",
    "        \n",
    "    df.to_csv(f'./{section_number}.csv', index=False ,encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "threads = list()\n",
    "starttime = time.time()\n",
    "#a = ['/categories/347','/categories/346']\n",
    "for element in your_section:\n",
    "    threads.append(threading.Thread(target=job, args=(element,)))\n",
    "for thread in threads:    \n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "print('Multithread took {} seconds'.format(time.time() - starttime))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
